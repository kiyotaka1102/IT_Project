{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -q faiss-cpu\n","!pip install -q git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -q translate\n","!pip install -q underthesea==1.3.5a3\n","!pip install -q underthesea[deep]\n","!pip install -q pyvi\n","!pip install -q langdetect\n","!pip install -q googletrans==3.1.0a0\n","!pip install -q peft\n","!pip install bitsandbytes\n","!pip install transformers\n","!pip install flash-attn\n","!pip install -U sentence-transformers\n","!pip install xformers"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","import clip\n","from PIL import Image\n","import faiss\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import math\n","import googletrans\n","import translate\n","import glob\n","import underthesea\n","import sys\n","import time\n","from tqdm import tqdm\n","from pyvi import ViUtils, ViTokenizer\n","from difflib import SequenceMatcher\n","from langdetect import detect\n","from pathlib import Path\n","import re"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/duong/Documents/AIC2024_UTE_AI_Unknown/src\n","/home/duong/Documents/AIC2024_UTE_AI_Unknown/src/notebook\n","/home/duong/Documents/AIC2024_UTE_AI_Unknown\n"]}],"source":["ROOT = Path(os.getcwd()).resolve()\n","\n","# Add ROOT to sys.path\n","sys.path.append(str(ROOT))\n","\n","# Determine the working directory\n","if len(ROOT.parents) > 1:\n","    WORK_DIR = ROOT.parents[0]\n","else:\n","    WORK_DIR = ROOT  # Fallback to ROOT if it doesn't have enough parents\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","\n","print(WORK_DIR)\n","print(ROOT)\n","\n","# Determine the working directory\n","if len(WORK_DIR.parents) > 1:\n","    path_root = WORK_DIR.parents[0]\n","else:\n","    path_root = WORK_DIR  # Fallback to ROOT if it doesn't have enough parents\n","\n","print(path_root)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:21<00:00, 10.66s/it]\n"]}],"source":["des_path =  f\"{WORK_DIR}/working/dicts/npy_clip\"\n","paths = f\"{path_root}/data/keyframes\"\n","\n","\n","for keyframe in tqdm(os.listdir(paths)):\n","  path_keyframe = os.path.join(paths,keyframe)\n","  video_paths = sorted(glob.glob(f\"{path_keyframe}/*/\"))\n","  video_paths = ['/'.join(i.split('/')[:-1]) for i in video_paths]\n","\n","  start_time = time.time()\n","  for vd_path in video_paths:\n","\n","    re_feats = []\n","    keyframe_paths = glob.glob(f'{vd_path}/*.jpg')\n","    keyframe_paths = sorted(keyframe_paths, key=lambda x : x.split('/')[-1].replace('.jpg',''))\n","\n","    for keyframe_path in keyframe_paths:\n","      image = preprocess(Image.open(keyframe_path)).unsqueeze(0).to(device)\n","\n","      with torch.no_grad():\n","          image_feats = model.encode_image(image)\n","\n","      image_feats /= image_feats.norm(dim=-1, keepdim=True)\n","      image_feats = image_feats.detach().cpu().numpy().astype(np.float16).flatten()\n","\n","      re_feats.append(image_feats)\n","\n","    name_npy = vd_path.split('/')[-1]\n","\n","# Construct output file path\n","    outfile = os.path.join(des_path, f'{name_npy}.npy')\n","\n","# Ensure the directory exists before saving\n","    os.makedirs(des_path, exist_ok=True)\n","    np.save(outfile, re_feats)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved /home/duong/Documents/AIC2024_UTE_AI_Unknown/src/working/dicts/bin_clip/faiss_CLIP_cosine.bin\n"]}],"source":["def process_name(name: int):\n","    return \"0\"*(6-len(str(name))) + str(name)\n","\n","def sort_key(file_path):\n","    file_name = os.path.basename(file_path)\n","    match = re.match(r'(\\D+)(\\d+)_(V)(\\d+)', file_name)\n","    if match:\n","        prefix = match.group(1)\n","        number = int(match.group(2))\n","        suffix_number = int(match.group(4))\n","        return (prefix, number, suffix_number)\n","    return (file_name, 0, 0)\n","\n","\n","def write_bin_file_clip(bin_path: str, npy_path: str  ,method='cosine', feature_shape= 512): # Edit 512, 768\n","  if method in 'L2':\n","    index = faiss.IndexFlatL2(feature_shape)\n","  elif method in 'cosine':\n","    index = faiss.IndexFlatIP(feature_shape)\n","  else:\n","    assert f\"{method} not supported\"\n","\n","  npy_files = glob.glob(os.path.join(npy_path, \"*.npy\"))\n","  npy_files_sorted = sorted(npy_files, key=sort_key)\n","\n","  for npy_file in npy_files_sorted:\n","    feats = np.load(npy_file)\n","    index.add(feats)\n","\n","  faiss.write_index(index, os.path.join(bin_path, f\"faiss_CLIP_{method}.bin\"))\n","\n","  print(f'Saved {os.path.join(bin_path, f\"faiss_CLIP_{method}.bin\")}')\n","\n","write_bin_file_clip(bin_path = f\"{WORK_DIR}/working/dicts/bin_clip\", npy_path = f\"{WORK_DIR}/working/dicts/npy_clip\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":4}
